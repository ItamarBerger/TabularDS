{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview of a regression assignment \n",
    "Attempting to fit Life Expectancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'wcwidth'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Machine learning library\n",
    "import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducing the Life Expectancy dataset -- Exploratory Data Analysis (EDA)\n",
    "##### The goal of this phase is to understand the different features and relations between them and w.r.t. the target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CSV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.read_csv(\"./data/Life Expectancy Data.csv\",index_col='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.columns = dtf.columns.str.strip()\n",
    "dtf = dtf.drop(columns=['Hepatitis B', 'GDP', 'Diphtheria','percentage expenditure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.rename(columns = lambda c: c.replace(' ', ''), inplace=True)\n",
    "dtf.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the target feature - \"Lifexpectancy\": Using a histogram\n",
    "Our main goal at this point is to examine the highest correlations (in absolute value - also taking into account strong negative correlations) between a feature and the target col (Life Expectancy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_corr = 0.3\n",
    "\n",
    "df_numeric = dtf.drop(columns=dtf.select_dtypes(include=['object']).columns)\n",
    "target = 'Lifeexpectancy'\n",
    "corr = df_numeric.corr()\n",
    "corr_abs = corr.abs()\n",
    "ser_corr = corr_abs.nlargest(len(df_numeric),target)[target]\n",
    "cols_above_corr_limit = list(ser_corr[ser_corr.values > min_val_corr].index)\n",
    "df_corr = df_numeric[cols_above_corr_limit]\n",
    "\n",
    "correlations = df_corr.corr()[target].drop(target)\n",
    "\n",
    "# Create a bar plot of the correlations with the target\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=correlations.index, y=correlations.values, palette='inferno')\n",
    "plt.title('Correlation with Target Column')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above wel demonstrate that the features 'schooling' and'Income'  have high positive correlation with life expectancy. \n",
    "On the other hand 'AdultMortality' has strong negative correlation to the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.hist(figsize=(20, 16), bins=50, xlabelsize=8, ylabelsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above demonstrate a number of key points:\n",
    "1. The distribution of thinnes 1-19 years is almost identical to theoe of thinnes 5-9 years. Thus we would drop the latter.\n",
    "2. It seems like almost 50% of the IBM values in the dtaset are 50 and higher. Which is extremly high (According to BMI score calcuator), thus we'd probably drop that column, since its distribution in the dataset isn't realistic.\n",
    "3. Life Expectancy's distribution is almost normal around 73-74.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'd like to take a deeper loook into the Lifeexpectancy column on our dataset with respect to the categorical 'Status' feature (Developed/Developing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "status_counts = dtf['Status'].value_counts()\n",
    "axes[0].pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=90, colors=['#0fffc7','#6693ff','#99ff99'])\n",
    "\n",
    "sns.boxplot(x='Status', y='Lifeexpectancy', data=dtf.dropna(), ax = axes[1])\n",
    "axes[1].set_title('Boxplot of Lifeexpectancy by Status')\n",
    "dtf =  dtf.dropna()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=dtf,x='Year',y='Lifeexpectancy')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(19, 5))\n",
    "dtf.groupby(pd.cut(dtf['Schooling'],5))['Lifeexpectancy'].mean().plot(kind='line',ax=axes[0])\n",
    "dtf.groupby(pd.cut(dtf['Incomecompositionofresources'],11))['Lifeexpectancy'].mean().plot(kind='line',ax=axes[1])\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Correlations to the target feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualzing relevant feature-pair relations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the plot above is difficult to read, we can bin the year column then group by and view the mean price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Split to Train and Test, then see the target feature distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train, dtf_test = train_test_split(dtf, \n",
    "                      test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "dtf_train.Lifeexpectancy.hist(ax=ax)\n",
    "dtf_test.Lifeexpectancy.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat the one-hot attributes and drop the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# convert categorical feature into one-hot encoding representation\n",
    "dummy_train = pd.get_dummies(dtf_train['Status'], prefix='Status')\n",
    "dummy_test = pd.get_dummies(dtf_test['Status'], prefix='Status')\n",
    "# update test and train datasets with the new column of 'Status' Feature\n",
    "dtf_train = pd.concat([dtf_train, dummy_train], axis=1).drop(columns='Status')\n",
    "dtf_test = pd.concat([dtf_test, dummy_test], axis=1).drop(columns='Status')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate X from y\n",
    "X_train = dtf_train.drop('Lifeexpectancy',axis=1)\n",
    "X_test = dtf_test.drop('Lifeexpectancy',axis=1)\n",
    "\n",
    "y_train = dtf_train['Lifeexpectancy']\n",
    "y_test = dtf_test['Lifeexpectancy']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate how good is the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many metrics exist for evaluating the regression over the test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_percentage_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with r^2: R Squared is the squared sum of differences from the actual values and the predicted values, divided by the squared differences from the mean (i.e var*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> What is a good R2 score and how do we improve it? This is not an ML class, a better question is what does the score \"means\"\n",
    "<br>\n",
    "High R2 means that the model \"explains\" a lot of the variance, i.e. that the behaviour is \"predicted\".\n",
    "It *doesn't* directly imply whether the model is right!\n",
    "<br>\n",
    "Let's see more metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Perc Error (Σ(|y - pred|/y)/n):\",\"{:,.3f}\".format(mean_absolute_percentage_error(y_test,prediction)))\n",
    "print(\"Mean Absolute Error (Σ|y - pred|/n):\", \"{:,.0f}\".format(mean_absolute_error(y_test, prediction)))\n",
    "print(\"Root Mean Squared Error (sqrt(Σ(y - pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(mean_squared_error(y_test, prediction))))\n",
    "\n",
    "## residuals\n",
    "residuals = y_test - prediction\n",
    "max_error = residuals.abs().max()\n",
    "max_idx = residuals[residuals==max_error]\n",
    "#max_true, max_pred = y_test.loc[max_idx], prediction[max_idx]\n",
    "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the true values against the predicted values. \n",
    "<br> In the regression line, the predicted values are always on the function y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "sns.scatterplot(x= prediction,y = y_test,ax=ax,color='blue')\n",
    "sns.lineplot(x = prediction,y = prediction,ax=ax,color='black')\n",
    "plt.title(\"model's test prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already learn that our bigger mistakes are when the sale price is larger.\n",
    "<br>\n",
    "Lets take a deeper looks into the 'residuals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,5))\n",
    "sns.scatterplot(x=prediction,y=residuals,ax=ax[0])\n",
    "sns.lineplot(prediction,0,ax=ax[0],color='black')\n",
    "ax[0].set_title(\"Residuals (Abs)\")\n",
    "sns.scatterplot(prediction,residuals/y_test,ax=ax[1])\n",
    "sns.lineplot(x=prediction,y=0,ax=ax[1],color='black')\n",
    "ax[1].set_title(\"Residuals (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that we have \"small\" mistakes and \"big\" mistakes. Let's look into that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_res=residuals/y_test\n",
    "rel_res=rel_res.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many time did our model achieve low estimation error (error less than 5%)?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_res[rel_res<0.05])/len(rel_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about more than 20%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_res[rel_res>0.2])/len(rel_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first interested in feature importance.\n",
    "<br>\n",
    "In the simple linear regression model, we can look at the learned coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model coefficients:\\n\")\n",
    "for i in range(len(X_train.columns)):\n",
    "    print(X_train.columns[i], \"=\", model.coef_[i].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since our features are not normalized, it is hard to assess which ones are the most important.\n",
    "<br>\n",
    "For that, we use SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sample = X_train.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, shap_sample)\n",
    "shap_values = explainer(shap_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we can also do that to explain the prediction of a single element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was our biggest relative error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_res[rel_res==rel_res.max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = rel_res[rel_res==rel_res.max()].index[0]\n",
    "pred_series=pd.Series(prediction,index=rel_res.index)\n",
    "pred_series[max_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the real price was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[max_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this problematic point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[max_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ordinal_id= X_test.index.get_loc(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxenplot(dtf.GrLivArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(test_shap_values[max_ordinal_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(residuals[residuals>50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_examples = X_test.loc[residuals[residuals>50000].index]\n",
    "bad_examples_shap_values = explainer(bad_examples)\n",
    "shap.plots.beeswarm(bad_examples_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get even a deeper understanding regarding our model's mistakes, we can compare the distributions of our mistakes to good predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_estimates = X_test.loc[residuals[residuals>50000].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_estimates = X_test.loc[rel_res[rel_res<0.05].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "good_estimates.GrLivArea.hist(ax=ax,color='blue')\n",
    "over_estimates.GrLivArea.hist(ax=ax,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our overestimas contains \"larger\" apartments.\n",
    "<br> While the model correctly understood that larger apartments are often more expensive, this is not always correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(over_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
