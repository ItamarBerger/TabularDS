{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX_NCznlNHye"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ItamarBerger/TabularDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi_KucCvRDGx",
        "outputId": "a3e539ad-85f2-4603-ec1a-e29523b8b1d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TabularDS' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/TabularDS/final_project/code/data/online_retail.csv')\n",
        "# data = retails.copy()"
      ],
      "metadata": {
        "id": "dZwX40EVPMdy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retails.head()\n",
        "# print(len(retails))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "zVGaG2KbQL92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "025a6d2d-a161-45c6-e516-b33a387cd9b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  InvoiceNo StockCode                          Description  Quantity  \\\n",
              "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
              "1    536365     71053                  WHITE METAL LANTERN         6   \n",
              "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
              "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
              "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
              "\n",
              "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
              "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
              "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
              "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
              "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
              "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68bb4c49-ad27-4b97-8fa7-d5dbce99cac0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>536365</td>\n",
              "      <td>85123A</td>\n",
              "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>536365</td>\n",
              "      <td>71053</td>\n",
              "      <td>WHITE METAL LANTERN</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>536365</td>\n",
              "      <td>84406B</td>\n",
              "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
              "      <td>8</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>2.75</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029G</td>\n",
              "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029E</td>\n",
              "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68bb4c49-ad27-4b97-8fa7-d5dbce99cac0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68bb4c49-ad27-4b97-8fa7-d5dbce99cac0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68bb4c49-ad27-4b97-8fa7-d5dbce99cac0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0187f35b-1941-4ba4-beed-3b1d09b9fc17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0187f35b-1941-4ba4-beed-3b1d09b9fc17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0187f35b-1941-4ba4-beed-3b1d09b9fc17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Apriori for rule mining"
      ],
      "metadata": {
        "id": "rU_fNB6EUTNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
        "data.dropna(subset=['InvoiceNo', 'Description'], inplace=True)\n",
        "\n",
        "transactions = data.groupby('InvoiceNo')['Description'].apply(list).tolist()"
      ],
      "metadata": {
        "id": "2tLlnwOvabf-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "# Sample a smaller subset\n",
        "transactions = transactions[:50]\n",
        "\n",
        "# Optimize TransactionEncoder using sparse format\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions, sparse=True)\n",
        "df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
        "\n",
        "# Apply Apriori with a higher support threshold (adjust as needed)\n",
        "frequent_itemsets = apriori(df, min_support=0.05, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "if not frequent_itemsets.empty:\n",
        "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "    print(rules)\n",
        "else:\n",
        "    print(\"No frequent itemsets found. Try lowering min_support.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Zrk63WVodLtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top rules by lift\n",
        "# top_lift_rules = rules.sort_values('lift', ascending=False).head(100)\n",
        "# print(top_lift_rules)\n"
      ],
      "metadata": {
        "id": "Mch0QcYun0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import networkx as nx\n",
        "# from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# # Create a directed graph\n",
        "# G = nx.DiGraph()\n",
        "# narrow_rules = rules[0:25]\n",
        "# # Add nodes and directed edges\n",
        "# for _, rule in narrow_rules.iterrows():\n",
        "#     antecedent = ', '.join(list(rule['antecedents']))\n",
        "#     consequent = ', '.join(list(rule['consequents']))\n",
        "\n",
        "#     # Add a directed edge from antecedent to consequent\n",
        "#     G.add_edge(antecedent, consequent, weight=rule['lift'], support=rule['support'], confidence=rule['confidence'])\n",
        "\n",
        "# # Draw the directed graph\n",
        "# plt.figure(figsize=(12, 12))\n",
        "# pos = nx.spring_layout(G, k=0.3, iterations=20)  # Layout for the graph\n",
        "\n",
        "# # Draw the nodes and edges\n",
        "# nx.draw_networkx_nodes(G, pos, node_size=200, node_color='lightblue', alpha=0.7)\n",
        "# nx.draw_networkx_edges(G, pos, width=2.0, alpha=0.5, arrowstyle='->', arrowsize=10)\n",
        "# nx.draw_networkx_labels(G, pos, font_size=10, font_color='black')\n",
        "\n",
        "# # Add edge labels (optional, if you want to display lift, confidence, or support)\n",
        "# # edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "# # nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "\n",
        "# plt.title(\"Association Rules Directed Graph\")\n",
        "# plt.axis('off')\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4pHXBq27f-Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly.graph_objects as go\n",
        "# import networkx as nx\n",
        "# from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# # Example association rules (you need to load your own rules here)\n",
        "# # Example: rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "\n",
        "# # Create a directed graph\n",
        "# G = nx.DiGraph()\n",
        "\n",
        "# # Add nodes and directed edges\n",
        "# for _, rule in narrow_rules.iterrows():\n",
        "#     antecedent = ', '.join(list(rule['antecedents']))\n",
        "#     consequent = ', '.join(list(rule['consequents']))\n",
        "\n",
        "#     # Add a directed edge from antecedent to consequent\n",
        "#     G.add_edge(antecedent, consequent, weight=rule['lift'], support=rule['support'], confidence=rule['confidence'])\n",
        "\n",
        "# # Get positions of nodes using a layout\n",
        "# pos = nx.spring_layout(G, k=0.3, iterations=20)\n",
        "\n",
        "# # Get edge and node information for Plotly\n",
        "# edge_x = []\n",
        "# edge_y = []\n",
        "# for edge in G.edges():\n",
        "#     x0, y0 = pos[edge[0]]\n",
        "#     x1, y1 = pos[edge[1]]\n",
        "#     edge_x.append(x0)\n",
        "#     edge_y.append(y0)\n",
        "#     edge_x.append(x1)\n",
        "#     edge_y.append(y1)\n",
        "\n",
        "# # Node positions\n",
        "# node_x = [pos[node][0] for node in G.nodes()]\n",
        "# node_y = [pos[node][1] for node in G.nodes()]\n",
        "\n",
        "# # Create hover text for nodes (empty text for default)\n",
        "# hover_text = [node for node in G.nodes()]\n",
        "\n",
        "# # Create the plotly figure\n",
        "# fig = go.Figure()\n",
        "\n",
        "# # Add directed edges with arrows (using annotations for arrows)\n",
        "# for edge in G.edges():\n",
        "#     x0, y0 = pos[edge[0]]\n",
        "#     x1, y1 = pos[edge[1]]\n",
        "\n",
        "#     # Add edge line\n",
        "#     fig.add_trace(go.Scatter(x=[x0, x1], y=[y0, y1],\n",
        "#                              line=dict(width=1, color='gray'),\n",
        "#                              mode='lines',\n",
        "#                              showlegend=False))\n",
        "\n",
        "#     # Add arrow (using annotations)\n",
        "#     fig.add_annotation(\n",
        "#         x=x1, y=y1,\n",
        "#         ax=x0, ay=y0,\n",
        "#         axref=\"x\", ayref=\"y\", xref=\"x\", yref=\"y\",\n",
        "#         showarrow=True, arrowhead=2, arrowsize=1,\n",
        "#         arrowcolor='gray', opacity=0.7\n",
        "#     )\n",
        "\n",
        "# # Add nodes to the plot\n",
        "# fig.add_trace(go.Scatter(x=node_x, y=node_y,\n",
        "#                          mode='markers',\n",
        "#                          hoverinfo='text',  # This ensures text shows on hover only\n",
        "#                          hovertext=hover_text,  # Set hovertext to show item names on hover\n",
        "#                          marker=dict(color='skyblue', size=10, line=dict(width=1, color='black'))))\n",
        "\n",
        "# # Add edge labels (optional: you can use lift or other metrics)\n",
        "# edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "# for edge, label in edge_labels.items():\n",
        "#     x0, y0 = pos[edge[0]]\n",
        "#     x1, y1 = pos[edge[1]]\n",
        "#     fig.add_trace(go.Scatter(x=[(x0+x1)/2], y=[(y0+y1)/2],\n",
        "#                              text=[f'Lift: {label:.2f}'],\n",
        "#                              mode='text',\n",
        "#                              showlegend=False))\n",
        "\n",
        "# # Update layout settings for better visualization\n",
        "# fig.update_layout(title=\"Association Rules Directed Graph (Interactive)\",\n",
        "#                   showlegend=False,\n",
        "#                   hovermode='closest',\n",
        "#                   xaxis=dict(showgrid=False, zeroline=False),\n",
        "#                   yaxis=dict(showgrid=False, zeroline=False))\n",
        "\n",
        "# # Show the plot\n",
        "# fig.show()\n"
      ],
      "metadata": {
        "id": "IJrqXXbgiEl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "\n",
        "# # Plot support vs confidence\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.scatterplot(x='support', y='confidence', data=rules, hue='lift', palette='coolwarm', size='lift', sizes=(50, 300))\n",
        "# plt.title(\"Support vs Confidence with Lift\")\n",
        "# plt.xlabel('Support')\n",
        "# plt.ylabel('Confidence')\n",
        "# plt.show()\n",
        "\n",
        "# # Plot lift distribution\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(rules['lift'], kde=True)\n",
        "# plt.title(\"Lift Distribution\")\n",
        "# plt.xlabel('Lift')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "p1uXodl4gAMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calc stats for baseline apriori\n",
        "mean_supp = rules['support'].mean()\n",
        "mean_conf = rules['confidence'].mean()\n",
        "mean_lift = rules['lift'].mean()\n",
        "print(f'''Mean Support: {mean_supp}\n",
        "Mean Confidence: {mean_conf}\n",
        "Mean Lift: {mean_lift}''')\n"
      ],
      "metadata": {
        "id": "6rCHjQyimCfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster items + Apriori\n"
      ],
      "metadata": {
        "id": "-qqhjLNWXnsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 🔹 Step 1: Convert Transactions to One-Hot Encoded Format\n",
        "te = TransactionEncoder()\n",
        "one_hot = te.fit_transform(transactions)\n",
        "df = pd.DataFrame(one_hot, columns=te.columns_)\n",
        "\n",
        "# 🔹 Step 2: Determine Optimal Number of Clusters (Elbow Method)\n",
        "distortions = []\n",
        "K_range = range(2, 10)  # Try different values of K\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(df)\n",
        "    distortions.append(sum(np.min(cdist(df, kmeans.cluster_centers_, 'euclidean'), axis=1)) / df.shape[0])\n",
        "\n",
        "# 🔹 Step 3: Plot the Elbow Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K_range, distortions, marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Distortion')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()\n",
        "\n",
        "# 🔹 Step 4: Fit K-Means with Optimal k\n",
        "optimal_k = 4  # Choose based on the Elbow Method\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['Cluster'] = kmeans.fit_predict(df)\n",
        "\n",
        "# 🔹 Step 5: Print Cluster Assignments\n",
        "print(df[['Cluster']])\n"
      ],
      "metadata": {
        "id": "zJds2I7wXq9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Function to process a single cluster\n",
        "def process_cluster(cluster_id, df):\n",
        "    print(f\"\\nProcessing Cluster {cluster_id}...\")\n",
        "\n",
        "    # Extract transactions for the cluster\n",
        "    cluster_data = df[df['Cluster'] == cluster_id].drop(columns=['Cluster'])\n",
        "\n",
        "    # Run Apriori\n",
        "    frequent_itemsets = apriori(cluster_data, min_support=0.05, use_colnames=True)\n",
        "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "\n",
        "    print(f\"Cluster {cluster_id}: {len(rules)} rules generated.\")\n",
        "\n",
        "    return cluster_id, {\"frequent_itemsets\": frequent_itemsets, \"rules\": rules}\n",
        "\n",
        "# Run clustering in parallel\n",
        "num_cores = 2  # Uses all available cores\n",
        "cluster_results = dict(\n",
        "    Parallel(n_jobs=num_cores)(\n",
        "        delayed(process_cluster)(cluster_id, df) for cluster_id in sorted(df['Cluster'].unique())\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "dOb8TpaDX2Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize dictionary to store average metrics per cluster\n",
        "cluster_metrics = {}\n",
        "\n",
        "for cluster_id, data in cluster_results.items():\n",
        "    rules = data[\"rules\"]\n",
        "\n",
        "    if not rules.empty:\n",
        "        avg_support = rules[\"support\"].mean()\n",
        "        avg_confidence = rules[\"confidence\"].mean()\n",
        "        avg_lift = rules[\"lift\"].mean()\n",
        "    else:\n",
        "        avg_support, avg_confidence, avg_lift = 0, 0, 0  # Handle empty clusters\n",
        "\n",
        "    cluster_metrics[cluster_id] = {\n",
        "        \"Avg Support\": avg_support,\n",
        "        \"Avg Confidence\": avg_confidence,\n",
        "        \"Avg Lift\": avg_lift\n",
        "    }\n",
        "\n",
        "# Convert dictionary to DataFrame for easier plotting\n",
        "metrics_df = pd.DataFrame.from_dict(cluster_metrics, orient=\"index\")\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "id": "HEVQidHkX6ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using item-based CF for rules mining"
      ],
      "metadata": {
        "id": "T2N5TnA2kZdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yS_Pq9QcdKTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "transactions = transactions\n",
        "\n",
        "\n",
        "def calculate_jaccard_similarity(transaction_matrix):\n",
        "    \"\"\"Calculate Jaccard similarity between all item pairs\"\"\"\n",
        "    binary_matrix = (transaction_matrix > 0).astype(int)\n",
        "    jaccard_dist = pdist(binary_matrix.T, metric='jaccard')\n",
        "    jaccard_sim = 1 - squareform(jaccard_dist)\n",
        "    return pd.DataFrame(jaccard_sim, index=transaction_matrix.columns, columns=transaction_matrix.columns)\n",
        "\n",
        "def calculate_item_means(transaction_matrix):\n",
        "    \"\"\"Calculate mean occurrence (probability) for each item\"\"\"\n",
        "    return transaction_matrix.mean()\n",
        "\n",
        "def calculate_recommendation_score(transaction_items, candidate_item, item_similarity_df, transaction_matrix):\n",
        "    \"\"\"\n",
        "    Calculate recommendation score using adjusted formula for binary ratings:\n",
        "    score(u,i) = Σj similarity(i,j)(r(u,j) - r̄j) / Σj |similarity(i,j)| + r̄i\n",
        "    where:\n",
        "    - r(u,j) is 1 if item j is in transaction, 0 otherwise\n",
        "    - r̄j is the mean occurrence of item j across all transactions\n",
        "    - r̄i is the mean occurrence of candidate item i\n",
        "    \"\"\"\n",
        "    # Get mean occurrences for all items\n",
        "    item_means = calculate_item_means(transaction_matrix)\n",
        "\n",
        "    numerator = 0\n",
        "    denominator = 0\n",
        "\n",
        "    # Calculate the weighted sum of deviations from mean\n",
        "    for item in transaction_items:\n",
        "        similarity = item_similarity_df.loc[candidate_item, item]\n",
        "        # r(u,j) is 1 since item is in transaction\n",
        "        rating_deviation = 1 - item_means[item]  # (r(u,j) - r̄j)\n",
        "        numerator += similarity * rating_deviation\n",
        "        denominator += abs(similarity)\n",
        "\n",
        "    # Add the candidate item's mean occurrence\n",
        "    mean_i = item_means[candidate_item]\n",
        "\n",
        "    if denominator != 0:\n",
        "        score = (numerator / denominator) + mean_i\n",
        "    else:\n",
        "        score = mean_i\n",
        "\n",
        "    return score\n",
        "\n",
        "def generate_transaction_rules(transactions):\n",
        "    # Create binary transaction matrix\n",
        "    item_list = sorted(set([item for sublist in transactions for item in sublist]))\n",
        "    transaction_matrix = pd.DataFrame(0, index=range(len(transactions)), columns=item_list)\n",
        "    for idx, transaction in enumerate(transactions):\n",
        "        for item in transaction:\n",
        "            transaction_matrix.at[idx, item] = 1\n",
        "\n",
        "    # Calculate item similarity\n",
        "    item_similarity_df = calculate_jaccard_similarity(transaction_matrix)\n",
        "\n",
        "    # Generate recommendations\n",
        "    recommendations = []\n",
        "\n",
        "    for transaction in transactions:\n",
        "        scores = {}\n",
        "\n",
        "        # Calculate scores for all possible items not in transaction\n",
        "        for candidate_item in item_list:\n",
        "            if candidate_item not in transaction:\n",
        "                score = calculate_recommendation_score(\n",
        "                    transaction,\n",
        "                    candidate_item,\n",
        "                    item_similarity_df,\n",
        "                    transaction_matrix\n",
        "                )\n",
        "                scores[candidate_item] = score\n",
        "\n",
        "        if scores:\n",
        "            # Get best recommendation\n",
        "            best_item = max(scores.items(), key=lambda x: x[1])\n",
        "\n",
        "            recommendation = {\n",
        "                'transaction': transaction,\n",
        "                'recommended_item': best_item[0],\n",
        "                'score': best_item[1]\n",
        "            }\n",
        "            recommendations.append(recommendation)\n",
        "\n",
        "    return pd.DataFrame(recommendations)\n",
        "\n",
        "\n",
        "# Usage\n",
        "rules_df = generate_transaction_rules(transactions)\n",
        "\n"
      ],
      "metadata": {
        "id": "rK22Gt1sd1SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules_df.head()"
      ],
      "metadata": {
        "id": "FWlxHBZO6ECV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate support, confidence, lift, and more\n",
        "def calculate_metrics(rule, all_transactions):\n",
        "    antecedent = set(rule['transaction'])\n",
        "    consequent = set([rule['recommended_item']])\n",
        "\n",
        "    # Calculate support\n",
        "    support_antecedent = sum(1 for transaction in all_transactions if antecedent.issubset(set(transaction))) / len(all_transactions)\n",
        "    support_consequent = sum(1 for transaction in all_transactions if consequent.issubset(set(transaction))) / len(all_transactions)\n",
        "    support_rule = sum(1 for transaction in all_transactions if antecedent.issubset(set(transaction)) and consequent.issubset(set(transaction))) / len(all_transactions)\n",
        "\n",
        "    # Calculate confidence\n",
        "    confidence = support_rule / support_antecedent if support_antecedent != 0 else 0\n",
        "\n",
        "    # Calculate lift\n",
        "    lift = confidence / support_consequent if support_consequent != 0 else 0\n",
        "\n",
        "    # Calculate leverage\n",
        "    expected_support = support_antecedent * support_consequent\n",
        "    leverage = support_rule - expected_support\n",
        "\n",
        "    # Calculate conviction\n",
        "    conviction = (1 - support_consequent) / (1 - confidence) if confidence < 1 else np.inf\n",
        "\n",
        "    return {\n",
        "        'support_antecedent': support_antecedent,\n",
        "        'support_consequent': support_consequent,\n",
        "        'support_rule': support_rule,\n",
        "        'confidence': confidence,\n",
        "        'lift': lift,\n",
        "        'leverage': leverage,\n",
        "        'conviction': conviction\n",
        "    }\n",
        "\n",
        "# Calculate metrics for each rule\n",
        "metrics = []\n",
        "for _, rule in rules_df.iterrows():\n",
        "    rule_metrics = calculate_metrics(rule, transactions)\n",
        "    metrics.append(rule_metrics)\n",
        "\n",
        "# Add metrics to the DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Combine the original rules with the calculated metrics\n",
        "df_rules = pd.concat([rules_df, metrics_df], axis=1)\n",
        "\n",
        "print(df_rules)"
      ],
      "metadata": {
        "id": "NHiRhE7LL1hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the rules by average rating and select the top 100\n",
        "top_100_rules = df_rules.sort_values(by='conviction', ascending=False).head(100)\n",
        "\n",
        "# Display the top 100 rules\n",
        "print(top_100_rules[['lift', 'conviction']])"
      ],
      "metadata": {
        "id": "Qwi65LG_6DPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_100_rules[['antecedents', 'consequents', 'lift', 'rating', 'confidence', 'support']])\n"
      ],
      "metadata": {
        "id": "Do-1UYX7zrZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform item-based CF for rule mining\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_item_ratings(invoice_items, item_sim_df):\n",
        "    \"\"\"\n",
        "    Calculate predicted rating for items not in the invoice.\n",
        "    Rating(Item X) = sum(sim(Item X, item_in_invoice)) / sum(similarities)\n",
        "    \"\"\"\n",
        "    scores = {}\n",
        "    norm_factor = 0\n",
        "\n",
        "    for item in invoice_items:\n",
        "        similar_items = item_sim_df[item].drop(index=invoice_items, errors=\"ignore\")  # Remove existing items\n",
        "        for sim_item, similarity in similar_items.items():\n",
        "            scores[sim_item] = scores.get(sim_item, 0) + similarity  # Aggregate similarity scores\n",
        "            norm_factor += similarity  # Normalize by sum of similarities\n",
        "\n",
        "    if norm_factor == 0:\n",
        "        return {}\n",
        "\n",
        "    # Normalize scores\n",
        "    for item in scores:\n",
        "        scores[item] /= norm_factor\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "cY8zXVcCWeJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "threshold = 0.2  # Min rating for an item to be considered\n",
        "\n",
        "rules = []\n",
        "for invoice in tqdm(df_onehot.index,desc=\"Processing Raiting\"):\n",
        "    existing_items = df_onehot.columns[df_onehot.loc[invoice] == 1].tolist()\n",
        "    predicted_ratings = compute_item_ratings(existing_items, item_sim_df)\n",
        "\n",
        "    # Select items with rating above threshold\n",
        "    recommended_items = {item for item, score in predicted_ratings.items() if score > threshold}\n",
        "\n",
        "    if recommended_items:\n",
        "        rules.append((set(existing_items), recommended_items))  # Format: {A, B, C} → {D, F}\n",
        "\n",
        "rules_df = pd.DataFrame(rules, columns=[\"Antecedent\", \"Consequent\"])\n"
      ],
      "metadata": {
        "id": "iSw9rfrObaDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute Confidence and Lift\n",
        "def compute_rule_metrics(rules_df, df_onehot):\n",
        "    total_invoices = len(df_onehot)\n",
        "    metrics = []\n",
        "\n",
        "    for _, row in rules_df.iterrows():\n",
        "        antecedent = row[\"Antecedent\"]\n",
        "        consequent = row[\"Consequent\"]\n",
        "\n",
        "        support_A = (df_onehot[list(antecedent)].sum(axis=1) == len(antecedent)).mean()\n",
        "        support_B = (df_onehot[list(consequent)].sum(axis=1) == len(consequent)).mean()\n",
        "        support_A_B = ((df_onehot[list(antecedent)].sum(axis=1) == len(antecedent)) &\n",
        "                       (df_onehot[list(consequent)].sum(axis=1) == len(consequent))).mean()\n",
        "\n",
        "        confidence = support_A_B / support_A if support_A > 0 else 0\n",
        "        lift = confidence / support_B if support_B > 0 else 0\n",
        "        interestingness = confidence * lift  # Tradeoff metric\n",
        "\n",
        "        metrics.append((antecedent, consequent, confidence, lift, interestingness))\n",
        "\n",
        "    return pd.DataFrame(metrics, columns=[\"Antecedent\", \"Consequent\", \"Confidence\", \"Lift\", \"Interestingness\"])\n",
        "\n",
        "rules_eval_df = compute_rule_metrics(rules_df, df_onehot)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BhFRbIQYXfNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Top 100 Most Interesting Rules\n",
        "top_100_rules = rules_eval_df.sort_values(by=\"Interestingness\", ascending=False).head(100)\n",
        "print(top_100_rules)"
      ],
      "metadata": {
        "id": "1G8jxc4mXGN5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}